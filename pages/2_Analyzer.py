import streamlit as st
import pandas as pd
import io
from modules.db_utils import init_supabase_client
from modules.analysis_utils import (    
    get_all_sentence_data, 
    estimate_snr50_for_sentence,
    analyze_all_sentences,
    display_analysis_metrics,
    create_psychometric_plot,
    create_combined_psychometric_plot
)

st.set_page_config(page_title="ì ìˆ˜ ë¶„ì„", layout="wide")
st.title("Quick-SIN ê°œë³„ ë¬¸ì¥ ë¶„ì„ í˜ì´ì§€ (SNR-50 ì¶”ì •) ğŸ“Š")

# --- í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
supabase = init_supabase_client()
if not supabase:
    st.stop()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”: ë¶„ì„ ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„°ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ìµœì í™”) ---
if 'analysis_results_df' not in st.session_state:
    st.session_state.analysis_results_df = None
if 'data_snr_range' not in st.session_state:
    st.session_state.data_snr_range = None
if 'temp_download_data' not in st.session_state:
    st.session_state.temp_download_data = None
if 'total_data_rows' not in st.session_state:
    st.session_state.total_data_rows = None

st.header("0. ì „ì²´ ì›ë³¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
download_use_dummy = st.checkbox(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„°(dummy_ ì ‘ë‘ì‚¬) ë‹¤ìš´ë¡œë“œ",
    value=False,
    key='download_dummy_check',
    help="ì²´í¬ ì‹œ session_idê°€ 'dummy_'ë¡œ ì‹œì‘í•˜ëŠ” ë°ì´í„°ë§Œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì²´í¬ í•´ì œ ì‹œ ê·¸ ì™¸ì˜ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
)

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³ , st.download_buttonì„ ì¦‰ì‹œ ìƒì„±í•©ë‹ˆë‹¤.
if st.button("ğŸ“¥ ì „ì²´ ë°ì´í„° ì¡°íšŒ ë° ë‹¤ìš´ë¡œë“œ ì¤€ë¹„"):
    with st.spinner("ì „ì²´ ë°ì´í„°ë¥¼ DBì—ì„œ ì¡°íšŒ ì¤‘ì…ë‹ˆë‹¤..."):
        all_data_df = get_all_sentence_data(supabase, use_dummy_prefix=download_use_dummy)
        if not all_data_df.empty:
            # ì´ ë°ì´í„° row ìˆ˜ ì €ì¥
            st.session_state.total_data_rows = len(all_data_df)
            
            # SNR ë²”ìœ„ ì €ì¥ (ê·¸ë˜í”„ìš©)
            st.session_state.data_snr_range = (
                all_data_df['snr_level'].min(),
                all_data_df['snr_level'].max()
            )
            
            with st.spinner("ì „ì²´ ë¬¸ì¥ì— ëŒ€í•œ SNR-50 ë¶„ì„ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state.analysis_results_df = analyze_all_sentences(all_data_df)
            
            # ë‹¤ìš´ë¡œë“œìš© CSV ë°ì´í„°ë¥¼ ì„ì‹œë¡œ ì €ì¥ (ë‹¤ìš´ë¡œë“œ í›„ ìë™ ì‚­ì œ)
            st.session_state.temp_download_data = all_data_df.to_csv(index=False).encode('utf-8-sig')
            
            st.success("ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ë¶„ì„í•˜ì—¬ ì„¸ì…˜ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ê³„ì† í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.session_state.analysis_results_df = None
            st.session_state.data_snr_range = None
            st.session_state.temp_download_data = None
            st.session_state.total_data_rows = None
            st.warning("ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë°ì´í„° ì´ˆê¸°í™” ë²„íŠ¼
cols_reset = st.columns([1, 1, 6])
with cols_reset[0]:
    if st.button("ğŸ§¹ ë°ì´í„° ì´ˆê¸°í™”"):
        st.session_state.analysis_results_df = None
        st.session_state.data_snr_range = None
        st.session_state.temp_download_data = None
        st.session_state.total_data_rows = None
        st.rerun()

# --- ì¡°íšŒ/ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ì„¸ì…˜ ìœ ì§€) ---
if st.session_state.temp_download_data is not None:
    analysis_results_df = st.session_state.analysis_results_df
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.success("ë°ì´í„° ì¡°íšŒ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ CSV íŒŒì¼ì„ ì €ì¥í•˜ì„¸ìš”.")
    st.download_button(
        label="ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ. í´ë¦­í•˜ì—¬ ì €ì¥ (CSV)",
        data=st.session_state.temp_download_data,
        file_name="all_qsin_scores.csv",
        mime="text/csv",
    )

    # ì „ì²´ ë°ì´í„° ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    st.header("ì „ì²´ ë°ì´í„° ë¶„ì„ ê²°ê³¼")
    if analysis_results_df is not None and not analysis_results_df.empty:
        st.success(f"ì´ {len(analysis_results_df)}ê°œ ë¬¸ì¥ì— ëŒ€í•œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë¶„ì„ì—ì„œ ì œì™¸ëœ ë¬¸ì¥ ì •ë³´ í‘œì‹œ
        if st.session_state.temp_download_data:
            full_df = pd.read_csv(io.StringIO(st.session_state.temp_download_data.decode('utf-8-sig')))
            all_ids = set(full_df['sentence_id'].unique())
            analyzed_ids = set(analysis_results_df['sentence_id'].unique())
            excluded_ids = sorted(list(all_ids - analyzed_ids))

            if excluded_ids:
                st.warning(f"âš ï¸ **{len(excluded_ids)}ê°œ**ì˜ ë¬¸ì¥ì´ ë¶„ì„ì—ì„œ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. (ë°ì´í„° ë¶€ì¡± ë˜ëŠ” ì •ë‹µë¥  ë¶ˆë³€)")
                with st.expander("ì œì™¸ëœ ë¬¸ì¥ ID ëª©ë¡ í™•ì¸"):
                    st.write(", ".join(map(str, excluded_ids)))

        # ë“±ê¸‰ë³„ í†µê³„
        st.subheader("ë“±ê¸‰ë³„ ë¬¸ì¥ ìˆ˜")

        # ë“±ê¸‰ ê¸°ì¤€ ì„ íƒ UI
        classification_method = st.radio(
            "ë“±ê¸‰ ë¶„ë¥˜ ê¸°ì¤€ ì„ íƒ",
            ("ì‚¬ë¶„ìœ„ìˆ˜(IQR) ê¸°ë°˜ (ê¶Œì¥)", "í‰ê·  Â± í‘œì¤€í¸ì°¨ ê¸°ë°˜"),
            index=0,
            horizontal=True,
            help="ë¶„ì„ëœ SNR-50 ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë“±ê¸‰ì„ ë‚˜ëˆ„ëŠ” ê¸°ì¤€ì„ ì„ íƒí•©ë‹ˆë‹¤."
        )

        if classification_method == "ì‚¬ë¶„ìœ„ìˆ˜(IQR) ê¸°ë°˜ (ê¶Œì¥)":
            st.info("""
            **ğŸ’¡ ì‚¬ë¶„ìœ„ìˆ˜(IQR) ê¸°ë°˜ ë¶„ë¥˜**
            
            ë°ì´í„°ì˜ ì¤‘ê°„ 50% ë²”ìœ„(IQR)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë“±ê¸‰ì„ ë§¤ê¹ë‹ˆë‹¤.
            - **Ideal**: -8.56 ~ -5.57 dB (Q1 ~ Q3)
            - **Acceptable**: -10.05 ~ -4.07 dB (Q1-0.5*IQR ~ Q3+0.5*IQR)
            """)
            ideal_range = (-8.56, -5.57)
            acceptable_range = (-10.05, -4.07)
        else:
            st.info("""
            **ğŸ’¡ í‰ê·  Â± í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë¶„ë¥˜**
            
            ë°ì´í„°ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ì¼ë°˜ì ì¸ í†µê³„ì  ê¸°ì¤€ì…ë‹ˆë‹¤.
            - **Ideal**: -8.13 ~ -5.98 dB (í‰ê·  Â± 0.5Ïƒ)
            - **Acceptable**: -9.21 ~ -4.90 dB (í‰ê·  Â± 1.0Ïƒ)
            """)
            ideal_range = (-8.13, -5.98)
            acceptable_range = (-9.21, -4.90)

        # ì„ íƒëœ ê¸°ì¤€ìœ¼ë¡œ Validity ì¬ê³„ì‚° (ExtrapolatedëŠ” ìœ ì§€)
        def reclassify_validity(row):
            if row['validity'] == 'Extrapolated':
                return 'Extrapolated'
            snr = row['snr_50']
            if ideal_range[0] <= snr <= ideal_range[1]:
                return 'Ideal'
            elif acceptable_range[0] <= snr <= acceptable_range[1]:
                return 'Acceptable'
            else:
                return 'Warning'

        # ì›ë³¸ ë°ì´í„° ë³´ì¡´ì„ ìœ„í•´ ë³µì‚¬ë³¸ ì‚¬ìš©
        display_df = analysis_results_df.copy()
        display_df['validity'] = display_df.apply(reclassify_validity, axis=1)

        validity_counts = display_df['validity'].value_counts()
        v_cols = st.columns(4)
        with v_cols[0]:
            st.metric("Ideal âœ…", f"{validity_counts.get('Ideal', 0)} ê°œ")
        with v_cols[1]:
            st.metric("Acceptable ğŸ‘", f"{validity_counts.get('Acceptable', 0)} ê°œ")
        with v_cols[2]:
            st.metric("Warning âš ï¸", f"{validity_counts.get('Warning', 0)} ê°œ")
        with v_cols[3]:
            st.metric("Extrapolated âš ï¸", f"{validity_counts.get('Extrapolated', 0)} ê°œ")

        st.subheader("ì „ì²´ í†µê³„")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ë°ì´í„° í–‰ ìˆ˜", f"{st.session_state.total_data_rows:,}")
        with col2:
            st.metric("ë¶„ì„ëœ ë¬¸ì¥ ìˆ˜", len(display_df))
        with col3:
            st.metric("ì¤‘ì•™ê°’(Median) SNR-50", f"{display_df['snr_50'].median():.2f} dB")

        st.subheader("ë¬¸ì¥ë³„ ë¶„ì„ ê²°ê³¼")
        # display_dfëŠ” ì´ë¯¸ ì¬ê³„ì‚°ëœ validityë¥¼ ê°€ì§€ê³  ìˆìŒ
        table_df = display_df.copy()
        table_df['snr_50'] = table_df['snr_50'].round(2)
        table_df['slope'] = table_df['slope'].round(2)
        if 'total_score_sum' in table_df.columns:
            table_df['total_score_sum'] = table_df['total_score_sum'].round(0)
        if 'avg_score' in table_df.columns:
            table_df['avg_score'] = table_df['avg_score'].round(2)
        
        st.dataframe(
            table_df,
            column_config={
                "sentence_id": "ë¬¸ì¥ ID",
                "full_sentence": st.column_config.TextColumn("ë¬¸ì¥", width="large"),
                "snr_50": "SNR-50 (dB)",
                "slope": "ê¸°ìš¸ê¸° (%/dB)",
                "validity": "ë“±ê¸‰",
                "total_score_sum": "ì´ ì ìˆ˜",
                "avg_score": "í‰ê·  ì ìˆ˜",
                "data_points": "ë°ì´í„° ìˆ˜",
                "snr_levels": "SNR ë ˆë²¨ ìˆ˜"
            },
            use_container_width=True
        )

        analysis_csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“Š ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
            data=analysis_csv,
            file_name="qsin_analysis_results.csv",
            mime="text/csv",
        )

        # ë¬¸ì¥ë³„ ë°ì´í„° ì‹œê°í™” (ëª¨ë“  ë¬¸ì¥ ê²¹ì³ì„œ)
        col_header, col_help = st.columns([0.85, 0.15])
        with col_header:
            st.subheader("ë¬¸ì¥ë³„ ë°ì´í„° ì‹œê°í™” (ì „ì²´ ê²¹ì³ë³´ê¸°)")
        with col_help:
            with st.popover("ğŸ’¡ ë„ì›€ë§"):
                st.markdown("""
                #### ê·¸ë˜í”„ í•´ì„ ê°€ì´ë“œ
                ì´ ê·¸ë˜í”„ëŠ” ëª¨ë“  ë¬¸ì¥ì˜ Psychometric Functionì„ ê²¹ì³ì„œ ë³´ì—¬ì£¼ì–´, ê° ë¬¸ì¥ì˜ ë‚œì´ë„ì™€ ë³€ë³„ë ¥ì„ í•œëˆˆì— ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

                - **ê¸°ìš¸ê¸° (ê³¡ì„ ì˜ ê°€íŒŒë¦„)**: **ë¬¸ì¥ì˜ ë³€ë³„ë ¥** ë˜ëŠ” **ì¸¡ì • í’ˆì§ˆ**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
                    - ê³¡ì„ ì´ ê°€íŒŒë¥¼ìˆ˜ë¡(ê¸°ìš¸ê¸° ê°’ì´ ë†’ì„ìˆ˜ë¡) SNR ë³€í™”ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ëŠ” ì¢‹ì€ ì¸¡ì • ë¬¸í•­ì…ë‹ˆë‹¤.

                - **SNR-50 (ë§ˆì»¤ì˜ xì¶• ìœ„ì¹˜ ë° ìƒ‰ìƒ)**: **ë¬¸ì¥ì˜ ë‚œì´ë„**ì™€ **ëª©í‘œê°’(2dB) ê·¼ì ‘ì„±**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
                    - `x` ê°’ì´ ë‚®ì„ìˆ˜ë¡ (ì™¼ìª½ì— ìˆì„ìˆ˜ë¡) ë” ì‰¬ìš´ ë¬¸ì¥ì…ë‹ˆë‹¤.
                    - **ë§ˆì»¤ ìƒ‰ìƒ ì˜ë¯¸:**
                        - ğŸŸ¢ **ë…¹ìƒ‰**: ì´ìƒì  ë‚œì´ë„ (Ideal)
                        - ğŸŸ  **ì£¼í™©ìƒ‰**: ìˆ˜ìš© ê°€ëŠ¥ ë‚œì´ë„ (Acceptable)
                        - ğŸ”´ **ë¹¨ê°„ìƒ‰**: ì£¼ì˜ í•„ìš” (Warning)
                        - âš« **íšŒìƒ‰**: ì‹ ë¢°ë„ ë‚®ì€ ì¶”ì •ì¹˜ (Extrapolated) - *ê·¸ë˜í”„ ë¯¸í‘œì‹œ*

                **ì¢‹ì€ ë¬¸ì¥ì„ ì„ ë³„í•˜ë ¤ë©´, `ë…¹ìƒ‰` ë˜ëŠ” `ì£¼í™©ìƒ‰` ë§ˆì»¤ë¥¼ ê°€ì§€ë©´ì„œ ê³¡ì„ ì´ ê°€íŒŒë¥¸(ê¸°ìš¸ê¸°ê°€ ë†’ì€) ë¬¸ì¥ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.**
                """)

        st.caption("ì´ 360ê°œ ë¬¸ì¥ì„ í•˜ë‚˜ì˜ ê·¸ë˜í”„ì— ê²¹ì³ì„œ í‘œì‹œí•©ë‹ˆë‹¤. ë¡œì§€ìŠ¤í‹± ê³¡ì„ ì˜ ìƒ‰ìƒì€ ê° ë¬¸ì¥ì˜ ë“±ê¸‰ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")

        available_sentence_ids = display_df['sentence_id'].tolist()
        selected_sentence_ids = available_sentence_ids

        if not selected_sentence_ids:
            st.info("ì‹œê°í™”í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            fig = create_combined_psychometric_plot(
                sentence_ids=selected_sentence_ids,
                include_logistic=True,
                include_mean=False,
                show_legend=False,
                precomputed_results=display_df,
                snr_range=st.session_state.data_snr_range,
                ideal_range=ideal_range,
                acceptable_range=acceptable_range
            )
            if fig:
                st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("ë¶„ì„ ê°€ëŠ¥í•œ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

st.divider()

# --- 1. ë¶„ì„í•  ë¬¸ì¥ ë° ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ ---
st.header("1. ë¶„ì„ ëŒ€ìƒ ì„ íƒ")
sentence_id_to_analyze = st.number_input(
    "ë¶„ì„í•  ë¬¸ì¥ ë²ˆí˜¸(index)",
    min_value=1,
    max_value=360,
    value=1,
    help="1ë¶€í„° 360 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”."
)
use_dummy_data = st.checkbox(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„°(dummy_ ì ‘ë‘ì‚¬)ë§Œ ì‚¬ìš©",
    value=False,
    key='analyze_dummy_check',
    help="ì²´í¬ ì‹œ session_idê°€ 'dummy_'ë¡œ ì‹œì‘í•˜ëŠ” ë°ì´í„°ë§Œ ë¶„ì„í•©ë‹ˆë‹¤. ì²´í¬ í•´ì œ ì‹œ ê·¸ ì™¸ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
)

if st.button(f"ğŸ” ë¬¸ì¥ {sentence_id_to_analyze}ë²ˆ ë°ì´í„° ë¶„ì„ ì‹¤í–‰"):
    try:
        # --- 2. ë°ì´í„° ë¡œë“œ ë° ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ (ë””ë²„ê¹…) ---
        st.header("2. ë°ì´í„° ì²˜ë¦¬ ê³¼ì • í™•ì¸")
        with st.spinner(f"DBì—ì„œ ë¬¸ì¥ {sentence_id_to_analyze}ë²ˆì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            processed_data = get_all_sentence_data(supabase, use_dummy_data, sentence_id_to_analyze)

        if processed_data.empty:
            st.error(f"ë¬¸ì¥ {sentence_id_to_analyze}ë²ˆì— ëŒ€í•œ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•œ SNR ë ˆë²¨ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:        
            st.info("ì„ íƒí•œ ë¬¸ì¥ì— ëŒ€í•´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒí•˜ê³  ì •ë‹µë¥ ì„ ê³„ì‚°í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

            full_sentence_text = processed_data['full_sentence'].iloc[0]
            st.markdown(f"**ë¶„ì„ ëŒ€ìƒ ë¬¸ì¥: \"{full_sentence_text}\"**")

            display_df = processed_data.drop(columns=['session_id', 'full_sentence', 'sentence_id', 'user_id'])
            st.dataframe(display_df)

            csv_data = processed_data.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ ì´ ë¬¸ì¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                data=csv_data,
                file_name=f"sentence_{sentence_id_to_analyze}_data.csv",
                mime="text/csv",
            )
            st.header("3. ë¶„ì„ ê²°ê³¼")
            with st.spinner("ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  SNR-50ì„ ì¶”ì •í•©ë‹ˆë‹¤..."):
                result = estimate_snr50_for_sentence(processed_data)

            status = result.get('status')
            if status == 'Success':
                snr50_val = result.get('snr_50')
                slope_val = result.get('slope')
                display_analysis_metrics(snr50_val, slope_val)
            else:
                st.error(f"ë¶„ì„ ì‹¤íŒ¨: **{status}**")
                st.warning("ë°ì´í„° ë¶„í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. ì‹ ë¢°ë„ ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 3ê°œ ì´ìƒì˜ ë‹¤ì–‘í•œ SNR ë ˆë²¨ì— ëŒ€í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

            # --- 4. ì‹œê°í™” ---
            st.header("4. Psychometric Function Curve")
            fig = create_psychometric_plot(processed_data, result, sentence_id_to_analyze)
            if fig:
                st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.info("ê°„í—ì ì¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìºì‹œë¥¼ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")
        if st.button("ğŸ”„ ìºì‹œ ì§€ìš°ê³  ì¬ì‹œë„"):
            st.cache_data.clear()
            st.rerun()