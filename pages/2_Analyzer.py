import streamlit as st
import pandas as pd
from modules.db_utils import init_supabase_client
from modules.analysis_utils import (    
    get_all_sentence_data, 
    estimate_snr50_for_sentence,
    analyze_all_sentences,
    display_analysis_metrics,
    create_psychometric_plot,
    create_combined_psychometric_plot
)

st.set_page_config(page_title="ì ìˆ˜ ë¶„ì„", layout="wide")
st.title("Quick-SIN ê°œë³„ ë¬¸ì¥ ë¶„ì„ í˜ì´ì§€ (SNR-50 ì¶”ì •) ğŸ“Š")

# --- í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
supabase = init_supabase_client()
if not supabase:
    st.stop()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”: ë¶„ì„ ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„°ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ìµœì í™”) ---
if 'analysis_results_df' not in st.session_state:
    st.session_state.analysis_results_df = None
if 'data_snr_range' not in st.session_state:
    st.session_state.data_snr_range = None
if 'temp_download_data' not in st.session_state:
    st.session_state.temp_download_data = None

st.header("0. ì „ì²´ ì›ë³¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
download_use_dummy = st.checkbox(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„°(dummy_ ì ‘ë‘ì‚¬) ë‹¤ìš´ë¡œë“œ",
    value=False,
    key='download_dummy_check',
    help="ì²´í¬ ì‹œ session_idê°€ 'dummy_'ë¡œ ì‹œì‘í•˜ëŠ” ë°ì´í„°ë§Œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì²´í¬ í•´ì œ ì‹œ ê·¸ ì™¸ì˜ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
)

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³ , st.download_buttonì„ ì¦‰ì‹œ ìƒì„±í•©ë‹ˆë‹¤.
if st.button("ğŸ“¥ ì „ì²´ ë°ì´í„° ì¡°íšŒ ë° ë‹¤ìš´ë¡œë“œ ì¤€ë¹„"):
    with st.spinner("ì „ì²´ ë°ì´í„°ë¥¼ DBì—ì„œ ì¡°íšŒ ì¤‘ì…ë‹ˆë‹¤..."):
        all_data_df = get_all_sentence_data(supabase, use_dummy_prefix=download_use_dummy)
        if not all_data_df.empty:
            # SNR ë²”ìœ„ ì €ì¥ (ê·¸ë˜í”„ìš©)
            st.session_state.data_snr_range = (
                all_data_df['snr_level'].min(),
                all_data_df['snr_level'].max()
            )
            
            with st.spinner("ì „ì²´ ë¬¸ì¥ì— ëŒ€í•œ SNR-50 ë¶„ì„ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state.analysis_results_df = analyze_all_sentences(all_data_df)
            
            # ë‹¤ìš´ë¡œë“œìš© CSV ë°ì´í„°ë¥¼ ì„ì‹œë¡œ ì €ì¥ (ë‹¤ìš´ë¡œë“œ í›„ ìë™ ì‚­ì œ)
            st.session_state.temp_download_data = all_data_df.to_csv(index=False).encode('utf-8-sig')
            
            st.success("ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ë¶„ì„í•˜ì—¬ ì„¸ì…˜ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ê³„ì† í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.session_state.analysis_results_df = None
            st.session_state.data_snr_range = None
            st.session_state.temp_download_data = None
            st.warning("ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë°ì´í„° ì´ˆê¸°í™” ë²„íŠ¼
cols_reset = st.columns([1, 1, 6])
with cols_reset[0]:
    if st.button("ğŸ§¹ ë°ì´í„° ì´ˆê¸°í™”"):
        st.session_state.analysis_results_df = None
        st.session_state.data_snr_range = None
        st.session_state.temp_download_data = None
        st.rerun()

# --- ì¡°íšŒ/ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ì„¸ì…˜ ìœ ì§€) ---
if st.session_state.temp_download_data is not None:
    analysis_results_df = st.session_state.analysis_results_df
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.success("ë°ì´í„° ì¡°íšŒ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ CSV íŒŒì¼ì„ ì €ì¥í•˜ì„¸ìš”.")
    st.download_button(
        label="ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ. í´ë¦­í•˜ì—¬ ì €ì¥ (CSV)",
        data=st.session_state.temp_download_data,
        file_name="all_qsin_scores.csv",
        mime="text/csv",
    )

    # ì „ì²´ ë°ì´í„° ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    st.header("ì „ì²´ ë°ì´í„° ë¶„ì„ ê²°ê³¼")
    if analysis_results_df is not None and not analysis_results_df.empty:
        st.success(f"ì´ {len(analysis_results_df)}ê°œ ë¬¸ì¥ì— ëŒ€í•œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ë¶„ì„ëœ ë¬¸ì¥ ìˆ˜", len(analysis_results_df))
        with col2:
            st.metric("í‰ê·  SNR-50", f"{analysis_results_df['snr_50'].mean():.2f} dB")
        with col3:
            st.metric("í‰ê·  ê¸°ìš¸ê¸°", f"{analysis_results_df['slope'].mean():.2f} %/dB")
        with col4:
            # Validity ë“±ê¸‰ë³„ ì¹´ìš´íŠ¸
            ideal_count = len(analysis_results_df[analysis_results_df['validity'] == 'Ideal'])
            st.metric("Ideal ë“±ê¸‰ ë¬¸ì¥ ìˆ˜", ideal_count)

        st.subheader("ë¬¸ì¥ë³„ ë¶„ì„ ê²°ê³¼")
        display_df = analysis_results_df.copy()
        display_df['snr_50'] = display_df['snr_50'].round(2)
        display_df['slope'] = display_df['slope'].round(2)
        if 'total_score_sum' in display_df.columns:
            display_df['total_score_sum'] = display_df['total_score_sum'].round(0)
        if 'avg_score' in display_df.columns:
            display_df['avg_score'] = display_df['avg_score'].round(2)
        
        st.dataframe(
            display_df,
            column_config={
                "sentence_id": "ë¬¸ì¥ ID",
                "full_sentence": st.column_config.TextColumn("ë¬¸ì¥", width="large"),
                "snr_50": "SNR-50 (dB)",
                "slope": "ê¸°ìš¸ê¸° (%/dB)",
                "validity": "ë“±ê¸‰",
                "total_score_sum": "ì´ ì ìˆ˜",
                "avg_score": "í‰ê·  ì ìˆ˜",
                "data_points": "ë°ì´í„° ìˆ˜",
                "snr_levels": "SNR ë ˆë²¨ ìˆ˜"
            },
            use_container_width=True
        )

        analysis_csv = analysis_results_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“Š ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
            data=analysis_csv,
            file_name="qsin_analysis_results.csv",
            mime="text/csv",
        )

        # ë¬¸ì¥ë³„ ë°ì´í„° ì‹œê°í™” (ëª¨ë“  ë¬¸ì¥ ê²¹ì³ì„œ)
        col_header, col_help = st.columns([0.85, 0.15])
        with col_header:
            st.subheader("ë¬¸ì¥ë³„ ë°ì´í„° ì‹œê°í™” (ì „ì²´ ê²¹ì³ë³´ê¸°)")
        with col_help:
            with st.popover("ğŸ’¡ ë„ì›€ë§"):
                st.markdown("""
                #### ê·¸ë˜í”„ í•´ì„ ê°€ì´ë“œ
                ì´ ê·¸ë˜í”„ëŠ” ëª¨ë“  ë¬¸ì¥ì˜ Psychometric Functionì„ ê²¹ì³ì„œ ë³´ì—¬ì£¼ì–´, ê° ë¬¸ì¥ì˜ ë‚œì´ë„ì™€ ë³€ë³„ë ¥ì„ í•œëˆˆì— ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

                - **ê¸°ìš¸ê¸° (ê³¡ì„ ì˜ ê°€íŒŒë¦„)**: **ë¬¸ì¥ì˜ ë³€ë³„ë ¥** ë˜ëŠ” **ì¸¡ì • í’ˆì§ˆ**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
                    - ê³¡ì„ ì´ ê°€íŒŒë¥¼ìˆ˜ë¡(ê¸°ìš¸ê¸° ê°’ì´ ë†’ì„ìˆ˜ë¡) SNR ë³€í™”ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ëŠ” ì¢‹ì€ ì¸¡ì • ë¬¸í•­ì…ë‹ˆë‹¤.

                - **SNR-50 (ë§ˆì»¤ì˜ xì¶• ìœ„ì¹˜ ë° ìƒ‰ìƒ)**: **ë¬¸ì¥ì˜ ë‚œì´ë„**ì™€ **ëª©í‘œê°’(2dB) ê·¼ì ‘ì„±**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
                    - `x` ê°’ì´ ë‚®ì„ìˆ˜ë¡ (ì™¼ìª½ì— ìˆì„ìˆ˜ë¡) ë” ì‰¬ìš´ ë¬¸ì¥ì…ë‹ˆë‹¤.
                    - **ë§ˆì»¤ ìƒ‰ìƒ ì˜ë¯¸:**
                        - ğŸŸ¢ **ë…¹ìƒ‰**: ì´ìƒì  ë‚œì´ë„ (0.5 ~ 3.5 dB)
                        - ğŸŸ  **ì£¼í™©ìƒ‰**: ìˆ˜ìš© ê°€ëŠ¥ ë‚œì´ë„ (-1.0 ~ 5.0 dB)
                        - ğŸ”´ **ë¹¨ê°„ìƒ‰**: ëª©í‘œ ë‚œì´ë„ì—ì„œ ë§ì´ ë²—ì–´ë‚¨
                        - âš« **íšŒìƒ‰**: ì‹ ë¢°ë„ ë‚®ì€ ì¶”ì •ì¹˜ (`Extrapolated`)

                **ì¢‹ì€ ë¬¸ì¥ì„ ì„ ë³„í•˜ë ¤ë©´, `ë…¹ìƒ‰` ë˜ëŠ” `ì£¼í™©ìƒ‰` ë§ˆì»¤ë¥¼ ê°€ì§€ë©´ì„œ ê³¡ì„ ì´ ê°€íŒŒë¥¸(ê¸°ìš¸ê¸°ê°€ ë†’ì€) ë¬¸ì¥ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.**
                """)

        st.caption("ì´ 360ê°œ ë¬¸ì¥ì„ í•˜ë‚˜ì˜ ê·¸ë˜í”„ì— ê²¹ì³ì„œ í‘œì‹œí•©ë‹ˆë‹¤. ë¡œì§€ìŠ¤í‹± ê³¡ì„ ì˜ ìƒ‰ìƒì€ ê° ë¬¸ì¥ì˜ ë“±ê¸‰ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")

        available_sentence_ids = analysis_results_df['sentence_id'].tolist()
        selected_sentence_ids = available_sentence_ids

        if not selected_sentence_ids:
            st.info("ì‹œê°í™”í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            fig = create_combined_psychometric_plot(
                sentence_ids=selected_sentence_ids,
                include_logistic=True,
                include_mean=False,
                show_legend=False,
                precomputed_results=analysis_results_df,
                snr_range=st.session_state.data_snr_range,
            )
            if fig:
                st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("ë¶„ì„ ê°€ëŠ¥í•œ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

st.divider()

# --- 1. ë¶„ì„í•  ë¬¸ì¥ ë° ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ ---
st.header("1. ë¶„ì„ ëŒ€ìƒ ì„ íƒ")
sentence_id_to_analyze = st.number_input(
    "ë¶„ì„í•  ë¬¸ì¥ ë²ˆí˜¸(index)",
    min_value=1,
    max_value=360,
    value=1,
    help="1ë¶€í„° 360 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”."
)
use_dummy_data = st.checkbox(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„°(dummy_ ì ‘ë‘ì‚¬)ë§Œ ì‚¬ìš©",
    value=False,
    key='analyze_dummy_check',
    help="ì²´í¬ ì‹œ session_idê°€ 'dummy_'ë¡œ ì‹œì‘í•˜ëŠ” ë°ì´í„°ë§Œ ë¶„ì„í•©ë‹ˆë‹¤. ì²´í¬ í•´ì œ ì‹œ ê·¸ ì™¸ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
)

if st.button(f"ğŸ” ë¬¸ì¥ {sentence_id_to_analyze}ë²ˆ ë°ì´í„° ë¶„ì„ ì‹¤í–‰"):
    try:
        # --- 2. ë°ì´í„° ë¡œë“œ ë° ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ (ë””ë²„ê¹…) ---
        st.header("2. ë°ì´í„° ì²˜ë¦¬ ê³¼ì • í™•ì¸")
        with st.spinner(f"DBì—ì„œ ë¬¸ì¥ {sentence_id_to_analyze}ë²ˆì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            processed_data = get_all_sentence_data(supabase, use_dummy_data, sentence_id_to_analyze)

        if processed_data.empty:
            st.error(f"ë¬¸ì¥ {sentence_id_to_analyze}ë²ˆì— ëŒ€í•œ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•œ SNR ë ˆë²¨ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:        
            st.info("ì„ íƒí•œ ë¬¸ì¥ì— ëŒ€í•´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒí•˜ê³  ì •ë‹µë¥ ì„ ê³„ì‚°í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

            full_sentence_text = processed_data['full_sentence'].iloc[0]
            st.markdown(f"**ë¶„ì„ ëŒ€ìƒ ë¬¸ì¥: \"{full_sentence_text}\"**")

            display_df = processed_data.drop(columns=['session_id', 'full_sentence', 'sentence_id'])
            st.dataframe(display_df)

            csv_data = processed_data.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ ì´ ë¬¸ì¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                data=csv_data,
                file_name=f"sentence_{sentence_id_to_analyze}_data.csv",
                mime="text/csv",
            )
            st.header("3. ë¶„ì„ ê²°ê³¼")
            with st.spinner("ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  SNR-50ì„ ì¶”ì •í•©ë‹ˆë‹¤..."):
                result = estimate_snr50_for_sentence(processed_data)

            status = result.get('status')
            if status == 'Success':
                snr50_val = result.get('snr_50')
                slope_val = result.get('slope')
                display_analysis_metrics(snr50_val, slope_val)
            else:
                st.error(f"ë¶„ì„ ì‹¤íŒ¨: **{status}**")
                st.warning("ë°ì´í„° ë¶„í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. ì‹ ë¢°ë„ ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 3ê°œ ì´ìƒì˜ ë‹¤ì–‘í•œ SNR ë ˆë²¨ì— ëŒ€í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

            # --- 4. ì‹œê°í™” ---
            st.header("4. Psychometric Function Curve")
            fig = create_psychometric_plot(processed_data, result, sentence_id_to_analyze)
            if fig:
                st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.info("ê°„í—ì ì¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìºì‹œë¥¼ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")
        if st.button("ğŸ”„ ìºì‹œ ì§€ìš°ê³  ì¬ì‹œë„"):
            st.cache_data.clear()
            st.rerun()